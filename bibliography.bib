@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@inproceedings{castro2020scalable,
  title={Scalable methods for computing state similarity in deterministic markov decision processes},
  author={Castro, Pablo Samuel},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={06},
  pages={10069--10076},
  year={2020}
}

@article{li2006towards,
  title={Towards a unified theory of state abstraction for MDPs.},
  author={Li, Lihong and Walsh, Thomas J and Littman, Michael L},
  journal={AI\&M},
  volume={1},
  number={2},
  pages={3},
  year={2006},
  publisher={Citeseer}
}

@article{givan2003equivalence,
  title={Equivalence notions and model minimization in Markov decision processes},
  author={Givan, Robert and Dean, Thomas and Greig, Matthew},
  journal={Artificial Intelligence},
  volume={147},
  number={1-2},
  pages={163--223},
  year={2003},
  publisher={Elsevier}
}

@article{ferns2011bisimulation,
  title={Bisimulation metrics for continuous Markov decision processes},
  author={Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  journal={SIAM Journal on Computing},
  volume={40},
  number={6},
  pages={1662--1714},
  year={2011},
  publisher={SIAM}
}

@inproceedings{ferns2014bisimulation,
  title={Bisimulation Metrics are Optimal Value Functions.},
  author={Ferns, Norman and Precup, Doina},
  booktitle={UAI},
  pages={210--219},
  year={2014}
}

@inproceedings{ferns2004metrics,
  title={Metrics for Finite Markov Decision Processes.},
  author={Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  booktitle={UAI},
  volume={4},
  pages={162--169},
  year={2004}
}

@article{zhang2020learning,
  title={Learning invariant representations for reinforcement learning without reconstruction},
  author={Zhang, Amy and McAllister, Rowan and Calandra, Roberto and Gal, Yarin and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.10742},
  year={2020}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@inproceedings{pan2022understanding,
  title={Understanding and mitigating the limitations of prioritized experience replay},
  author={Pan, Yangchen and Mei, Jincheng and Farahmand, Amir-massoud and White, Martha and Yao, Hengshuai and Rohani, Mohsen and Luo, Jun},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1561--1571},
  year={2022},
  organization={PMLR}
}

@inproceedings{fedus2020revisiting,
  title={Revisiting fundamentals of experience replay},
  author={Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
  booktitle={International Conference on Machine Learning},
  pages={3061--3071},
  year={2020},
  organization={PMLR}
}

@article{chen2023attention,
  title={Attention Loss Adjusted Prioritized Experience Replay},
  author={Chen, Zhuoying and Li, Huiping and Wang, Rizhong},
  journal={arXiv preprint arXiv:2309.06684},
  year={2023}
}

@article{castro2021mico,
  title={Mico: Improved representations via sampling-based state similarity for markov decision processes},
  author={Castro, Pablo Samuel and Kastner, Tyler and Panangaden, Prakash and Rowland, Mark},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={30113--30126},
  year={2021}
}

@article{abel2022theory,
  title={A theory of abstraction in reinforcement learning},
  author={Abel, David},
  journal={arXiv preprint arXiv:2203.00397},
  year={2022}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{de2018experience,
  title={Experience selection in deep reinforcement learning for control},
  author={De Bruin, Tim and Kober, Jens and Tuyls, Karl and Babu{\v{s}}ka, Robert},
  journal={Journal of Machine Learning Research},
  volume={19},
  number={9},
  pages={1--56},
  year={2018}
}

@article{zha2019experience,
  title={Experience replay optimization},
  author={Zha, Daochen and Lai, Kwei-Herng and Zhou, Kaixiong and Hu, Xia},
  journal={arXiv preprint arXiv:1906.08387},
  year={2019}
}

@article{kumar2020discor,
  title={Discor: Corrective feedback in reinforcement learning via distribution correction},
  author={Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18560--18572},
  year={2020}
}

@inproceedings{sun2020attentive,
  title={Attentive experience replay},
  author={Sun, Peiquan and Zhou, Wengang and Li, Houqiang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={5900--5907},
  year={2020}
}

@article{liu2021regret,
  title={Regret minimization experience replay in off-policy reinforcement learning},
  author={Liu, Xu-Hui and Xue, Zhenghai and Pang, Jingcheng and Jiang, Shengyi and Xu, Feng and Yu, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17604--17615},
  year={2021}
}

@inproceedings{lee2021sunrise,
  title={Sunrise: A simple unified framework for ensemble learning in deep reinforcement learning},
  author={Lee, Kimin and Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={6131--6141},
  year={2021},
  organization={PMLR}
}

@inproceedings{sinha2022experience,
  title={Experience replay with likelihood-free importance weights},
  author={Sinha, Samarth and Song, Jiaming and Garg, Animesh and Ermon, Stefano},
  booktitle={Learning for Dynamics and Control Conference},
  pages={110--123},
  year={2022},
  organization={PMLR}
}

@article{abate2024bisimulation,
  title={Bisimulation learning},
  author={Abate, Alessandro and Giacobbe, Mirco and Schnitzer, Yannik},
  journal={arXiv preprint arXiv:2405.15723},
  year={2024}
}

@book{baier2008principles,
  title={Principles of model checking},
  author={Baier, Christel and Katoen, Joost-Pieter},
  year={2008},
  publisher={MIT press}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  pages={9--44},
  year={1988},
  publisher={Springer}
}

@article{liu2023prioritized,
  title={Prioritized Trajectory Replay: A Replay Memory for Data-driven Reinforcement Learning},
  author={Liu, Jinyi and Ma, Yi and Hao, Jianye and Hu, Yujing and Zheng, Yan and Lv, Tangjie and Fan, Changjie},
  journal={arXiv preprint arXiv:2306.15503},
  year={2023}
}

@article{lee2019sample,
  title={Sample-efficient deep reinforcement learning via episodic backward update},
  author={Lee, Su Young and Sungik, Choi and Chung, Sae-Young},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{dai2021diversity,
  title={Diversity-based trajectory and goal selection with hindsight experience replay},
  author={Dai, Tianhong and Liu, Hengyan and Arulkumaran, Kai and Ren, Guangyu and Bharath, Anil Anthony},
  booktitle={PRICAI 2021: Trends in Artificial Intelligence: 18th Pacific Rim International Conference on Artificial Intelligence, PRICAI 2021, Hanoi, Vietnam, November 8--12, 2021, Proceedings, Part III 18},
  pages={32--45},
  year={2021},
  organization={Springer}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@article{mahmood2014weighted,
  title={Weighted importance sampling for off-policy learning with linear function approximation},
  author={Mahmood, A Rupam and Van Hasselt, Hado P and Sutton, Richard S},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@book{lindvall2002lectures,
  title={Lectures on the coupling method},
  author={Lindvall, Torgny},
  year={2002},
  publisher={Courier Corporation}
}

@book{villani2009optimal,
  title={Optimal transport: old and new},
  author={Villani, C{\'e}dric and others},
  volume={338},
  year={2009},
  publisher={Springer}
}

@article{lukaszyk2004new,
  title={A new concept of probability metric and its applications in approximation of scattered data sets},
  author={{\L}ukaszyk, Szymon},
  journal={Computational mechanics},
  volume={33},
  pages={299--304},
  year={2004},
  publisher={Springer}
}

@article{ladosz2022exploration,
  title={Exploration in deep reinforcement learning: A survey},
  author={Ladosz, Pawel and Weng, Lilian and Kim, Minwoo and Oh, Hyondong},
  journal={Information Fusion},
  volume={85},
  pages={1--22},
  year={2022},
  publisher={Elsevier}
}

@article{amin2021survey,
  title={A survey of exploration methods in reinforcement learning},
  author={Amin, Susan and Gomrokchi, Maziar and Satija, Harsh and Van Hoof, Herke and Precup, Doina},
  journal={arXiv preprint arXiv:2109.00157},
  year={2021}
}
@Book{jm3,
  author =       "Daniel Jurafsky and James H. Martin",
  title =        "Speech and Language Processing: An Introduction to
                 Natural Language Processing, Computational Linguistics,
                 and Speech Recognition with Language Models",
  year =         "2024",
  url = {https://web.stanford.edu/~jurafsky/slp3/},
  note = "Online manuscript released August 20, 2024",
  edition =         "3rd",
  }

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={30},
  number={1},
  year={2016}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@article{machado2018revisiting,
  title={Revisiting the arcade learning environment: Evaluation protocols and open problems for general agents},
  author={Machado, Marlos C and Bellemare, Marc G and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={61},
  pages={523--562},
  year={2018}
}

@inproceedings{todorov2012mujoco,
  title={MuJoCo: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE},
  doi={10.1109/IROS.2012.6386109}
}

@inproceedings{laskin2020curl,
  title={Curl: Contrastive unsupervised representations for reinforcement learning},
  author={Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={5639--5650},
  year={2020},
  organization={PMLR}
}

@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@article{lake2017building,
  title={Building machines that learn and think like people},
  author={Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
  journal={Behavioral and brain sciences},
  volume={40},
  pages={e253},
  year={2017},
  publisher={Cambridge University Press}
}

@article{tassa2018deepmind,
  title={Deepmind control suite},
  author={Tassa, Yuval and Doron, Yotam and Muldal, Alistair and Erez, Tom and Li, Yazhe and Casas, Diego de Las and Budden, David and Abdolmaleki, Abbas and Merel, Josh and Lefrancq, Andrew and others},
  journal={arXiv preprint arXiv:1801.00690},
  year={2018}
}

@article{ha2018world,
  title={World models},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1803.10122},
  year={2018}
}

@inproceedings{hafner2019learning,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle={International conference on machine learning},
  pages={2555--2565},
  year={2019},
  organization={PMLR}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@article{anand2019unsupervised,
  title={Unsupervised state representation learning in atari},
  author={Anand, Ankesh and Racah, Evan and Ozair, Sherjil and Bengio, Yoshua and C{\^o}t{\'e}, Marc-Alexandre and Hjelm, R Devon},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{castro2023kernel,
  title={A kernel perspective on behavioural metrics for markov decision processes},
  author={Castro, Pablo Samuel and Kastner, Tyler and Panangaden, Prakash and Rowland, Mark},
  journal={arXiv preprint arXiv:2310.19804},
  year={2023}
}

@article{zhao2019curiosity,
  title={Curiosity-driven experience prioritization via density estimation},
  author={Zhao, Rui and Tresp, Volker},
  journal={arXiv preprint arXiv:1902.08039},
  year={2019}
}